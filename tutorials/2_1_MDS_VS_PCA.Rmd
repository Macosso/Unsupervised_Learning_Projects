---
title: "2_1: MDS VS PCA"
author: "Joao Claudio Macosso"
date: "2023-03-15"
output:
  html_document:
    toc: true
    toc_float: True
    code_folding: hide
    df_print: paged
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=5, fig.height=3, message = F, warning = F)
```

# Introduction
Multidimensional scaling (MDS) and principal component analysis (PCA) are two popular methods for reducing the dimensionality of data. Although both methods have similarities, they differ in their goals, assumptions, and procedures. In this answer, we will discuss the similarities and differences between MDS and PCA in detail.

# Similarities:

### Dimensionality reduction
Both MDS and PCA are methods for reducing the dimensionality of data by transforming a set of high-dimensional variables into a smaller set of low-dimensional variables.

### Orthogonality
Both methods produce orthogonal dimensions, meaning that the new variables are uncorrelated with each other.

### Variance maximization
Both methods aim to maximize the amount of variance explained by the new variables.

# Differences:

### Goals
The primary goal of MDS is to find a low-dimensional representation of the data that preserves the pairwise distances between observations. In other words, MDS seeks to find a configuration of points in a low-dimensional space that best approximates the distances between the original points in a high-dimensional space. On the other hand, the primary goal of PCA is to find a set of orthogonal variables that explain the maximum amount of variance in the data.

### Assumptions
MDS assumes that the distances between observations in the high-dimensional space are a true reflection of the underlying similarities or dissimilarities between the observations. In other words, MDS assumes that the distance metric is reliable and meaningful. PCA assumes that the data are normally distributed and that the relationship between the variables is linear.

### Procedures
MDS transforms the distance matrix into a low-dimensional configuration of points using a variety of algorithms, including classical scaling, non-metric scaling, and metric scaling. PCA transforms the original variables into a new set of uncorrelated variables (called principal components) by performing a linear transformation of the data. PCA uses eigenvalue decomposition to determine the principal components.

### Interpretability
MDS produces a configuration of points in a low-dimensional space that represents the original data, making it easy to interpret and visualize the results. PCA produces a set of new variables that are linear combinations of the original variables, making it more difficult to interpret the results.

### Applicability
MDS is suitable for analyzing dissimilarities or similarities in any type of data, including categorical, ordinal, and continuous data. PCA is suitable for analyzing continuous data that are normally distributed and have linear relationships.


# Conclusion
In summary, MDS and PCA are both useful tools for reducing the dimensionality of data. MDS is primarily used for visualizing the similarities and dissimilarities between observations, while PCA is primarily used for identifying the underlying structure of the data by finding the most important variables that explain the most variation in the data. The choice between MDS and PCA depends on the research question, the type of data, and the goals of the analysis.




